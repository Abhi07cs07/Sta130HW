{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dd6e1ba",
   "metadata": {},
   "source": [
    "Answer1: \n",
    "\n",
    "The key factor that determines whether an idea can be tested statistically is measurability—whether the idea can be formulated into a testable statement with observable and quantifiable data. Ideas that cannot be tied to measurable outcomes cannot be tested statistically.\n",
    "\n",
    "A good null hypothesis meets the following criteria:\n",
    "Specific: The hypothesis should clearly define the population parameter and the hypothesized value.\n",
    "Measurable: Data can be collected to assess the plausibility of the hypothesis.\n",
    "Falsifiable: The hypothesis can be potentially rejected based on the evidence from the data.\n",
    "Default or Uninteresting: The null hypothesis often represents a \"no effect\" or \"no difference\" situation. This allows researchers to seek evidence against this default assumption and potentially support a more interesting alternative hypothesis.\n",
    "\n",
    "The null hypothesis (H0) asserts that there is no significant difference or effect, while the alternative hypothesis (H1 or Ha) suggests that there is a significant effect or difference. Hypothesis testing evaluates whether the data provides sufficient evidence to reject the null hypothesis in favor of the alternative.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Answer 2: \n",
    "\n",
    "The sentence in the video emphasizes that the result of hypothesis testing applies to the population, not just the sample used in the test. \n",
    "\n",
    "Here's how I would explain this distinction to a non-statistical audience:\n",
    "When we conduct a test, we're interested in knowing something about a larger group of people or things (the population), but since we can't test everyone or everything, we take a smaller group (a sample) to gather data. We calculate an average (or some statistic) from that sample, called the sample statistic (denoted as x with a bar on top for the sample mean). However, the purpose of the test is not to make conclusions about just the sample; it's to make an educated guess about the average of the entire population, which is the population parameter (denoted as μ).\n",
    "\n",
    "In hypothesis testing, we set up a null hypothesis (H0) that claims the population average (μ) is a specific value, say μ0. Then we use the data from the sample to test if that claim is likely to be true or not. The alternative hypothesis (HA) suggests that the population average is different from μ0.\n",
    "\n",
    "So, even though we calculate things based on the sample, the ultimate goal is to draw conclusions about the larger population, which is what matters for the test. The key point is that testing focuses on population characteristics, not just what we see in the sample.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Answer 3:\n",
    "\n",
    "When calculating a p-value, we \"imagine a world where the null hypothesis is true\" because we are assessing how likely it is to get our sample data under the assumption that the null hypothesis holds. Basically, we assume that the null hypothesis (H0) represents the reality, and then calculate how extreme or unusual our sample results are compared to what we'd expect in this hypothetical world.\n",
    "\n",
    "This is where the sampling distribution of the test statistic comes into play. The sampling distribution shows us all the possible outcomes (or test statistics) we could get if we repeatedly sampled from the population where H0 is true. The p-value tells us how far our observed result is from the center of that distribution (i.e., the expected result under H0). A small p-value means our observed result is very unusual in this \"null hypothesis world,\" which suggests that H0 might not be true.\n",
    "\n",
    "In short, we \"imagine\" the null hypothesis is true to use it as a reference point. If our data looks very different from what we'd expect under this assumption, it gives us evidence to reject the null hypothesis.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Answer 4:\n",
    "\n",
    "A smaller p-value makes the null hypothesis look more \"ridiculous\" because it indicates that the observed data is highly unlikely to occur if the null hypothesis were true. Let me explain how this works:\n",
    "\n",
    "When we test a hypothesis, we assume the null hypothesis is true. Based on this assumption, we calculate the test statistic, which is a number that summarizes how far our observed data deviates from what we expect under H0(stands for null hypothesis as outlined in previous responses). Then, we compare this test statistic to a theoretical sampling distribution—a distribution that shows all the possible values the test statistic could take if H0 were true.\n",
    "\n",
    "The p-value measures how extreme or unusual our observed test statistic is compared to this distribution. If the p-value is small, it means our test statistic is far from the center (the expected outcome under H0) and lies in the \"tail\" of the distribution, which suggests that the observed data is very unusual if H0 holds.\n",
    "\n",
    "In this case, the smaller the p-value, the less likely it is that the data we observed could have occurred by random chance under \\H0. In simple terms, the more extreme the observed result is, the more it contradicts what we'd expect if H0 were true. This makes the null hypothesis seem more and more \"ridiculous\" because it's hard to believe it could explain such unusual data.\n",
    "\n",
    "Thus, a small p-value gives strong evidence against the null hypothesis, suggesting that it may not be an accurate representation of reality.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Answer 5:\n",
    "\n",
    "To answer this properly, we need to \n",
    "\n",
    "1. Contextualize the problem:\n",
    "    The question is testing the hypothesis that there is no preference for a right or left head tilt when kissing,     i.e., the null hypothesis H0 assumes the population tilts their heads 50/50 to either side.\n",
    "    \n",
    "    Here, p{hat} (the sample proportion) is 0.645 (64.5%).\n",
    "    \n",
    "    The population parameter μ0 (null hypothesis assumption) is 0.50 (50%).\n",
    "    \n",
    "    The sample size nnn is 124 couples.\n",
    "    \n",
    "2. Imagine a world where H0 is true:\n",
    "    If the null hypothesis is true, we would expect couples to tilt their heads to the right or left 50% of the         time, just like flipping a fair coin.\n",
    "    \n",
    "    We can use a simulation or binomial test based on this \"50/50 coin-flipping\" model to calculate how unusual the     observed proportion (64.5%) is under this assumption.\n",
    "    \n",
    "3. Simulate a p-value:\n",
    "    We assume a binomial distribution where each couple has a 50% chance of tilting their head to the right, and we     simulate 124 couples repeatedly to calculate the number of right tilts.\n",
    "    \n",
    "    The p-value is the probability of observing a proportion as extreme as 64.5% (or more extreme) under the           assumption that the true proportion is 50%.\n",
    "    \n",
    "Let's proceed by calculating this p-value using the binomial distribution formula for a two-sided test.\n",
    "\n",
    "Steps for the Calculation:\n",
    "\n",
    "    Under the null hypothesis H0, the expected number of couples tilting their heads to the right is \n",
    "    0.5 x 124 = 62\n",
    "    \n",
    "    The observed number is 80.\n",
    "    \n",
    "    The p-value is the probability of observing 80 or more heads (right tilts) out of 124 trials in a binomial         distribution where p=0.5\n",
    "\n",
    "Let’s assume we simulate the distribution or compute the exact p-value using a binomial calculator.\n",
    "\n",
    "\n",
    "Interpretation:\n",
    "After calculating the p-value, we compare it against the thresholds in the table, leading to out conclusion. \n",
    "Conclusion:\n",
    "Based on the p-value, we will decide whether there is strong enough evidence to reject the null hypothesis in favor of the alternative hypothesis (that people do have a preference for tilting their heads right when kissing).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Answer 6:\n",
    "\n",
    "A smaller p-value cannot definitively prove that the null hypothesis is false. In hypothesis testing, a p-value measures the strength of the evidence against the null hypothesis, but it doesn't provide absolute proof.\n",
    "\n",
    "Regarding Fido (from the video analogy):\n",
    "\n",
    "A low p-value means the observed data is very unlikely under the null hypothesis (e.g., Fido being innocent), suggesting we might reject the null hypothesis. However, this does not prove guilt; it only indicates strong evidence against innocence.\n",
    "A high p-value suggests that the observed data is consistent with the null hypothesis, but it doesn't prove innocence either. It just means we don't have enough evidence to reject the null.\n",
    "In short, p-values help assess evidence, but they don't definitively prove guilt or innocence. There is no threshold for a p-value that proves something for certain; it only indicates how confident we might be in rejecting or retaining a hypothesis.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Answer 7:\n",
    "\n",
    "In a one-sided (one-tailed) test, we focus on deviations in only one direction—either testing for an increase or a decrease, but not both. This is in contrast to a two-sided (two-tailed) test, where we test for deviations in both directions (i.e., any significant difference, regardless of direction).\n",
    "\n",
    "To adapt the code for a one-sided test, we make changes to account for testing deviations in only one direction. Here's how that adjustment typically works in Python, assuming you're using bootstrapping or a similar method for computing the p-value.\n",
    "\n",
    "Key Changes in the Code:\n",
    "One-sided Hypothesis Setup:\n",
    "\n",
    "For a two-sided test, we compare the absolute difference between the sample statistic and the null hypothesis value. This considers deviations in both directions (higher or lower).\n",
    "For a one-sided test, we remove the absolute value and only consider deviations in one direction (greater than or less than the null hypothesis value, depending on the test).\n",
    "Here’s how we might change the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaa7689",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 sided test(Before)\n",
    "p_value = np.mean(np.abs(bootstrap_stats - null_hypothesis_value) >= np.abs(observed_stat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1211198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Sided test(After)\n",
    "p_value = np.mean(bootstrap_stats >= observed_stat)  # For a test where we expect the sample to be greater than the null hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db757bac",
   "metadata": {},
   "source": [
    "Interpretation:\n",
    "\n",
    "A two-sided test checks whether the sample statistic is either significantly larger or smaller than the null hypothesis.\n",
    "A one-sided test checks only one direction, so we are interested in either larger values (right-tailed test) or smaller values (left-tailed test). This reduces the range of extreme values considered, focusing only on the direction we hypothesize.\n",
    "\n",
    "\n",
    "But why the smaller p-value in One-sided Test\n",
    "the p-value is generally smaller in a one-sided test because we are only testing one direction. In a two-sided test, we split the significance level (alpha) between both tails of the distribution, making it harder to reject the null hypothesis since we're accounting for deviations in both directions.\n",
    "In a one-sided test, all the significance level is focused in one tail, so we have more statistical power to detect a deviation in that direction, which leads to a smaller p-value if the data shows the effect we are looking for.\n",
    "\n",
    "Summary of Changes:\n",
    "We remove the absolute value comparison to focus on one direction.\n",
    "The p-value is expected to be smaller because we are testing only one tail of the distribution, making it easier to find significance in the specified direction.\n",
    "Should we use a one-tailed test? That depends on the context—if we have a strong reason to believe that the deviation will occur in a specific direction (e.g., we expect the vaccine to increase effectiveness), a one-sided test is appropriate. If we don't know the direction of the effect, we should stick with a two-sided test.\n",
    "\n",
    "\n",
    "Answer8:\n",
    "\n",
    "In the original experiment, Bristol claimed she could discern whether milk or tea was poured first into a cup. Fisher, being a skeptical statistician, proposed a hypothesis test to evaluate whether her ability to identify the order was due to chance. Fisher designed the test with 8 cups of tea, where 4 had milk poured first and 4 had tea poured first. Bristol correctly identified the pouring order of all 8 cups.\n",
    "\n",
    "In this adapted experiment, we aim to test a similar hypothesis using a sample of 80 STA130 students. Each student is asked to taste one cup of tea and identify whether the milk or tea was poured first. Out of the 80 students, 49 correctly identified the pouring order.\n",
    "\n",
    "Relationship Between This Experiment and the Original\n",
    "The original experiment tested whether Bristol's ability to distinguish the order of pouring was real or simply due to chance. The current experiment tests whether a group of 80 students, selected randomly from STA130, can distinguish the order with a success rate greater than what would be expected by random guessing. However, while Bristol's ability was personal and specific to her, this experiment involves a more abstract concept: whether the general population of STA130 students has some ability to correctly identify the pouring order.\n",
    "\n",
    "Differences:\n",
    "Sample Size: In Fisher's original experiment, the sample size was 8, whereas, in this case, it is 80 students.\n",
    "Population: The population in Fisher's experiment was specific to Dr. Bristol's claimed skill, while here it represents a broader, generalized group of students who may or may not have any particular sensory ability related to tea tasting.\n",
    "\n",
    "Statements of the Null Hypothesis and Alternative Hypothesis\n",
    "Formal Null Hypothesis (H₀): STA130 students are guessing, meaning the probability of correctly identifying whether milk or tea was poured first is 0.5 (p = 0.5).\n",
    "Informal Statement of H₀: The students are just guessing, and they are as likely to be wrong as right, with no special ability to identify which was poured first.\n",
    "Alternative Hypothesis (H₁): STA130 students have some ability to correctly identify whether milk or tea was poured first, and the probability of success is greater than 0.5 (p > 0.5).\n",
    "Informal Statement of H₁: The students might have a real ability to detect whether the tea or milk was poured first, leading to more correct answers than expected by chance.\n",
    "\n",
    "\n",
    "Quantitative Analysis\n",
    "We will perform a formal hypothesis test to determine if the observed result (49 correct out of 80) is significantly higher than what we would expect by chance, assuming random guessing. The population parameter of interest is ppp, the probability of a student correctly identifying the order of pouring. Under the null hypothesis, p=0.5, which represents random guessing.\n",
    "\n",
    "To assess the validity of the null hypothesis, we use a binomial distribution model. The binomial distribution can be used to calculate the probability of obtaining 49 or more correct responses under the assumption of random guessing. We can also simulate a sampling distribution by repeatedly generating random results based on p=0.5 to estimate the p-value.\n",
    "\n",
    "The p-value is the probability of observing 49 or more correct identifications purely by chance under the null hypothesis. If the p-value is small (typically α=0.05), it suggests that the observed result is unlikely to have occurred by random guessing, providing evidence against the null hypothesis.\n",
    "Methodology Code and Explanations\n",
    "The following steps outline the quantitative analysis using Python, including both hypothesis testing and p-value calculation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ff51dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import binom\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Parameters\n",
    "n = 80  # Total number of students\n",
    "p = 0.5  # Probability of guessing correctly under the null hypothesis\n",
    "observed_successes = 49  # Number of students who correctly identified the pouring order\n",
    "\n",
    "# Calculate p-value using the binomial cumulative distribution function (right-tail)\n",
    "p_value = 1 - binom.cdf(observed_successes - 1, n, p)\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "\n",
    "# Confidence Interval Approach\n",
    "# Approximate confidence interval for the true proportion of students who can identify the pouring order\n",
    "sample_proportion = observed_successes / n\n",
    "standard_error = np.sqrt(p * (1 - p) / n)\n",
    "z = 1.96  # For a 95% confidence level\n",
    "\n",
    "ci_lower = sample_proportion - z * standard_error\n",
    "ci_upper = sample_proportion + z * standard_error\n",
    "print(f\"95% confidence interval: ({ci_lower:.4f}, {ci_upper:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8651774",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "p-value calculation: We compute the p-value by determining the probability of getting 49 or more correct identifications under the assumption that the students are randomly guessing (p = 0.5). This is a one-sided test since our alternative hypothesis is that students perform better than chance.\n",
    "Confidence interval: The confidence interval gives us a range of plausible values for the true proportion of students who can identify the pouring order. If the interval includes 0.5, it suggests the data is consistent with random guessing.\n",
    "\n",
    "\n",
    "Findings and Discussion\n",
    "p-value: The p-value quantifies the probability that we would observe 49 or more correct responses purely by chance if the students were guessing. A small p-value (less than 0.05) would indicate that the observed result is unlikely to be due to chance, and we would reject the null hypothesis.\n",
    "\n",
    "Confidence interval: The confidence interval for the proportion of students who can correctly identify the pouring order helps us understand the range of plausible values for this probability. If the interval does not include 0.5, it suggests evidence against random guessing.\n",
    "\n",
    "Conclusion Regarding the Null Hypothesis\n",
    "Based on the results of the p-value and confidence interval, we can draw one of two conclusions:\n",
    "\n",
    "Reject H₀: If the p-value is small (e.g., < 0.05), we reject the null hypothesis and conclude that the students' ability to identify the pouring order is significantly better than random guessing.\n",
    "Fail to Reject H₀: If the p-value is large (e.g., > 0.05), we fail to reject the null hypothesis, meaning the evidence is insufficient to conclude that the students are doing better than random guessing.\n",
    "\n",
    "So therefore, through formal hypothesis testing, we have examined whether the STA130 students can identify whether tea or milk was poured first with better accuracy than chance would suggest. The p-value and confidence interval provide quantitative evidence to support or refute the null hypothesis, and the decision to reject or fail to reject H₀ ultimately depends on these statistical results\n",
    "\n",
    "\n",
    "Chat gpt link: https://chatgpt.com/share/670efa7d-ccf4-8004-b871-5fecd4d3f0ba\n",
    "Summary: \n",
    "\n",
    "Here's a summary of our discussion:\n",
    "P-value Interpretation: The p-value is the probability of obtaining observed results (or more extreme results) assuming the null hypothesis is true. A smaller p-value provides stronger evidence against the null hypothesis, leading to rejection of H0H_0H0​, while a higher p-value suggests there is not enough evidence to reject it.\n",
    "\n",
    "Calculating P-value (Binomial Distribution): We discussed how to compute the p-value using the binomial cumulative distribution function (CDF) in Python. For a right-tailed test, you calculate the p-value as 1−binom.cdf(k−1,n,p)1 - \\text{binom.cdf}(k-1, n, p)1−binom.cdf(k−1,n,p), and for a two-sided test, you sum up the probabilities for both tails.\n",
    "\n",
    "\n",
    "Confidence Interval (CI): We explored how to calculate the confidence interval (CI) for a binomial proportion. Using the normal approximation method, we compute the standard error (SE), margin of error (ME), and then the CI. \n",
    "\n",
    "We also discussed the Clopper-Pearson method (exact method) using binom.interval() from the scipy.stats library, which is more accurate for small sample sizes or extreme probabilities.\n",
    "\n",
    "Each step included Python code to demonstrate how to calculate the p-value and confidence intervals for hypothesis testing.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
